{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary methods\n",
    "\n",
    "## Dataset for the exercise\n",
    "\n",
    "* [New York Times Comments](https://www.kaggle.com/aashita/nyt-comments/data), set of readers' comments to articles published in the New York Times.\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "The comments provide a perspective to the kinds of concerns people raise in discussions related to online articles. The point of this example is to try to construct a set of keywords for dictionary search that captures the readers\n",
    "' views about the New York Times and journalistic reporting. Try different sets of keywords iteratively and examine how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify keywords for dictionary search\n",
    "keywords = \"New York Times,NYT\"\n",
    "keywords = keywords.lower()\n",
    "keywords = keywords.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/nyt-comments/'\n",
    "files = os.listdir( path ) ## see all files in directory\n",
    "files = filter( lambda file_name: file_name.startswith(\"Comments\"), files ) ## choose only data files\n",
    "files = map( lambda file_name: path + file_name, files ) ## add path to file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "comments = 0\n",
    "\n",
    "# Iterate through the files and count comments which mention any of the keywords\n",
    "for file in files:\n",
    "    for entry in csv.DictReader( open( file ) ):\n",
    "        \n",
    "        comments += 1\n",
    "        \n",
    "        comment = entry['commentBody']\n",
    "        \n",
    "        ## work through several different keywords in the analysis\n",
    "        for keyword in keywords: \n",
    "            if keyword in comment.lower():\n",
    "                counter += 1\n",
    "                break\n",
    "\n",
    "print( counter, \"/\", comments, \"comments mention any of the keywords:\", ', '.join(keywords) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Try to think of other keywords that would make the search more comprehensive, while not producing excessive volumes of irrelevant material. Add these to the keywords above and rerun the script.\n",
    "* Are there any cases where the above code might not work? Modify the code to address these if possible.\n",
    "* The data has a `createDate` variable as well, which identifies when the comment was created. Based on this, try to look for some temporal trends in comment counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language analysis\n",
    "\n",
    "In many languages, different words can have different forms. For example, 'I have an apple' and 'I have several apples' convey almost the same information, similarly 'She had an apple' and 'She has an apple' are almost identical. In the Finnish language such cases abound, since words may have several forms thanks to the many suffixes.\n",
    "\n",
    "This complicates keyword-based analyses. One approach to reducing the complexity of language is to **stem** or **lemmatize** words into their basic form. Furthermore, tools such as the [Natural Language Toolkit](https://www.nltk.org/) enable parsing text to identify proper nouns, named entities or to determine whether a word is an adjective, noun etc.\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "The below code is a short example of stemming the words of a message. Replicate the keyword search above, but this time using proper stemmatization. Do the results change?\n",
    "\n",
    "After doing the search using stemming, try processing the resulting comments to create a Document-Term Matrix. You can also check the other code examples for hints on how this could be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'This is a longer example! Many words are included here, and we shall stem them all.'\n",
    "stemmed = ''\n",
    "\n",
    "for word in nltk.word_tokenize( message ):\n",
    "    stemmed += stemmer.stem( word ) + ' '\n",
    "    \n",
    "print( stemmed )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
